---
layout: post
title:  "Look, Read and Ask: Learning to Ask Questions by Reading Text in Images"
date:   2021-09-02 22:21:59 +00:00
image: images/textvqg.png
categories: research
author: "Soumya Shamarao Jahagirdar"
authors: "<strong>Soumya Shamarao Jahagirdar</strong>,  Shankar Gangisetty, Anand Mishra"
venue: "International Conference on Document Analysis and Recognition, <strong> (ICDAR) </strong>"
arxiv: https://arxiv.org/pdf/2211.12950.pdf
code: https://github.com/soumyasj/textVQG
website: https://sites.google.com/site/shankarsetty/research/textvqg
youtube: https://www.youtube.com/watch?v=31C2wSzCxpM 
---
We present a novel problem of text-based visual question generation or TextVQG in short. Given the recent growing interest of the document image analysis community in combining text understanding with conversational artificial intelligence, e.g., text-based visual question answering, TextVQG becomes an important task. TextVQG aims to generate a natural language question for a given input image and an automatically extracted text also known as OCR token from it such that the OCR token is an answer to the generated question. 

